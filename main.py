import joblib
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from keras.models import load_model
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

max_len = 100
# --- Load m√¥ h√¨nh ƒë√£ l∆∞u ---
nb_model = joblib.load('models/naive_bayes_model.pkl')
svm_model = joblib.load('models/linear_svc_model.pkl')
svc_model = joblib.load('models/svc_model.pkl')
tfidf = joblib.load('models/tfidf_vectorizer.pkl')
label_encoder = joblib.load('models/label_encoder.pkl')

# --- VƒÉn b·∫£n m·ªõi c·∫ßn ph√¢n lo·∫°i ---
new_texts = [
    "S·∫£n ph·∫©m n√†y r·∫•t t·ªá",
    "D·ªãch v·ª• tuy·ªát v·ªùi v√† nhanh ch√≥ng",
    "Ch·∫•t l∆∞·ª£ng trung b√¨nh, kh√¥ng qu√° ƒë·∫∑c bi·ªát"
]

# --- Vector h√≥a vƒÉn b·∫£n ---
new_tfidf = tfidf.transform(new_texts)

# --- D·ª± ƒëo√°n ---
pred_nb = nb_model.predict(new_tfidf)
pred_svm = svm_model.predict(new_tfidf)
pred_svc = svc_model.predict(new_tfidf)

# --- Gi·∫£i m√£ nh√£n ---
decoded_nb = label_encoder.inverse_transform(pred_nb)
decoded_svm = label_encoder.inverse_transform(pred_svm)
decoded_svc = label_encoder.inverse_transform(pred_svc)

# --- In k·∫øt qu·∫£ ---
for i in range(len(new_texts)):
    print(f"\nüìÑ VƒÉn b·∫£n: {new_texts[i]}")

    # Naive Bayes (c√≥ h·ªó tr·ª£ predict_proba)
    prob_nb = nb_model.predict_proba(new_tfidf[i])[0]
    confidence_nb = np.max(prob_nb) * 100
    print(f"  ü§ñ Naive Bayes ‚Üí {decoded_nb[i]} ({confidence_nb:.2f}%)")

    # Linear SVC kh√¥ng h·ªó tr·ª£ x√°c su·∫•t ‚Äî ta ch·ªâ hi·ªÉn th·ªã nh√£n
    print(f"  üß† Linear SVC  ‚Üí {decoded_svm[i]} (kh√¥ng c√≥ x√°c su·∫•t)")

    # SVC v·ªõi x√°c su·∫•t
    if hasattr(svc_model, "predict_proba"):
        prob_svc = svc_model.predict_proba(new_tfidf[i])[0]
        confidence_svc = np.max(prob_svc) * 100
        print(f"  üöÄ SVC         ‚Üí {decoded_svc[i]} ({confidence_svc:.2f}%)")
    else:
        print(f"  üöÄ SVC         ‚Üí {decoded_svc[i]} (kh√¥ng c√≥ x√°c su·∫•t)")


import tensorflow as tf

print("TensorFlow version:", tf.__version__)
print("Num GPUs Available:", len(tf.config.list_physical_devices('GPU')))
# tf.debugging.set_log_device_placement(True)

# Load m√¥ h√¨nh
model = load_model("models/text_classification_model.h5")

# Load tokenizer
with open("models/tokenizer.pkl", "rb") as f:
    tokenizer = pickle.load(f)

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu m·ªõi (v√≠ d·ª•)
new_texts = ["s·∫£n ph·∫©m c·ª±c b√¨nh th∆∞·ªùng nh∆∞ng d√πng r·∫•t t·ªët v√† hi·ªáu qu·∫£ ƒë√°ng ti·ªÅn"]
new_sequences = tokenizer.texts_to_sequences(new_texts)
new_pad = pad_sequences(new_sequences, maxlen=max_len, padding='post', truncating='post')

# D·ª± ƒëo√°n
predictions = model.predict(new_pad)
predicted_class = predictions.argmax(axis=-1)
print(f"D·ª± ƒëo√°n nh√£n: {predicted_class}")
